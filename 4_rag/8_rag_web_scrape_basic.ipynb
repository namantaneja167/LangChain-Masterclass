{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Define the persistent directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "db_dir = os.path.join(current_dir, \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_db_firecrawl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin crawling the website...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-03 01:11:30 - langchain_text_splitters.base:122 - WARNING] Created a chunk of size 14277, which is longer than the specified 1000\n",
      "[2024-08-03 01:11:30 - langchain_text_splitters.base:122 - WARNING] Created a chunk of size 6343, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished crawling the website.\n",
      "\n",
      "--- Document Chunks Information ---\n",
      "Number of document chunks: 14\n",
      "Sample chunk:\n",
      "Apple\n",
      "=====\n",
      "\n",
      "\n",
      "--- Creating vector store in d:\\Coding\\LangChain Masterclass\\4_rag\\db\\chroma_db_firecrawl ---\n",
      "--- Finished creating vector store in d:\\Coding\\LangChain Masterclass\\4_rag\\db\\chroma_db_firecrawl ---\n",
      "\n",
      "--- Relevant Documents ---\n",
      "Document 1:\n",
      "Apple\n",
      "=====\n",
      "\n",
      "Source: Unknown\n",
      "\n",
      "Document 2:\n",
      "[](/apple-intelligence/)\n",
      "\n",
      "### Apple Intelligence\n",
      "\n",
      "AI for the rest of us.\n",
      "\n",
      "Coming in beta this fall1\n",
      "\n",
      "[Learn more](/apple-intelligence/)\n",
      " [Watch the film](/105/media/us/apple-intelligence/2024/05be55cf-0af7-4356-8420-f83e72fdfe6f/films/product/apple-intelligence-product-tpl-us-2024_16x9.m3u8)\n",
      "\n",
      " [](/apple-vision-pro/)\n",
      "\n",
      "### Apple Vision Pro\n",
      "\n",
      "The era of spatial computing is here.\n",
      "\n",
      "[Learn more](/apple-vision-pro/)\n",
      " [Buy](/us/shop/goto/buy_vision/apple_vision_pro)\n",
      "\n",
      " [](/business/enterprise/)\n",
      "\n",
      "### Apple at Work\n",
      "\n",
      "Work. Like never before.\n",
      "\n",
      "[Learn more](/business/enterprise/)\n",
      "\n",
      " [](/apple-card/)\n",
      "\n",
      "### Apple Card\n",
      "\n",
      "Get up to 3% Daily Cash back with every purchase.\n",
      "\n",
      "[Learn more](/apple-card/)\n",
      " [Apply now](https://card.apple.com/apply/application?referrer=cid%3Dapy-200-10000036&start=false)\n",
      " [Apply now](https://wallet.apple.com/apple-card/setup/feature/ccs?referrer=cid%3Dapy-200-10000036)\n",
      "\n",
      " [](/us/shop/goto/trade_in)\n",
      "\n",
      "### Apple Trade In\n",
      "\n",
      "Get $170-$620 in credit when you trade in iPhone 11 or higher.2\n",
      "\n",
      "Source: Unknown\n",
      "\n",
      "Document 3:\n",
      "*   [Accessibility](/accessibility/)\n",
      "    \n",
      "*   [Education](/education-initiative/)\n",
      "    \n",
      "*   [Environment](/environment/)\n",
      "    \n",
      "*   [Inclusion and Diversity](/diversity/)\n",
      "    \n",
      "*   [Privacy](/privacy/)\n",
      "    \n",
      "*   [Racial Equity and Justice](/racial-equity-justice-initiative/)\n",
      "    \n",
      "*   [Supply Chain](/supply-chain/)\n",
      "    \n",
      "\n",
      "### About Apple About Apple\n",
      "\n",
      "*   [Newsroom](/newsroom/)\n",
      "    \n",
      "*   [Apple Leadership](/leadership/)\n",
      "    \n",
      "*   [Career Opportunities](/careers/us/)\n",
      "    \n",
      "*   [Investors](https://investor.apple.com/)\n",
      "    \n",
      "*   [Ethics & Compliance](/compliance/)\n",
      "    \n",
      "*   [Events](/apple-events/)\n",
      "    \n",
      "*   [Contact Apple](/contact/)\n",
      "    \n",
      "\n",
      "More ways to shop: [Find an Apple Store](/retail/)\n",
      " or [other retailer](https://locate.apple.com/)\n",
      " near you. Or call 1-800-MY-APPLE.\n",
      "\n",
      "[United States](/choose-country-region/ \"Choose your country or region\")\n",
      "\n",
      "Copyright © 2024 Apple Inc. All rights reserved.\n",
      "\n",
      "Source: Unknown\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_vector_store():\n",
    "    \"\"\"Crawl the website, split the content, create embeddings, and persist the vector store.\"\"\"\n",
    "    # Define the Firecrawl API key\n",
    "    api_key = os.getenv(\"FIRECRAWL_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"FIRECRAWL_API_KEY environment variable not set\")\n",
    "    \n",
    "    # Step 1: Crawl the website using FireCrawlLoader\n",
    "    print(\"Begin crawling the website...\")\n",
    "    loader = FireCrawlLoader(\n",
    "        api_key=api_key, url=\"https://apple.com\", mode=\"scrape\"\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    print(\"Finished crawling the website.\")\n",
    "    \n",
    "    # Convert metadata values to strings if they are lists\n",
    "    for doc in docs:\n",
    "        for key, value in doc.metadata.items():\n",
    "            if isinstance(value, list):\n",
    "                doc.metadata[key] = \", \".join(map(str, value))\n",
    "                \n",
    "    # Step 2: Split the crawled content into chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    \n",
    "    # Display information about the split documents\n",
    "    print(\"\\n--- Document Chunks Information ---\")\n",
    "    print(f\"Number of document chunks: {len(split_docs)}\")\n",
    "    print(f\"Sample chunk:\\n{split_docs[0].page_content}\\n\")\n",
    "    \n",
    "    # Step 3: Create embeddings for the document chunks\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    print(f\"\\n--- Creating vector store in {persistent_directory} ---\")\n",
    "    db = Chroma.from_documents(split_docs, embeddings, persist_directory=persistent_directory)\n",
    "    \n",
    "    print(f\"--- Finished creating vector store in {persistent_directory} ---\")\n",
    "    \n",
    "# Check if the Chroma vector store already exists\n",
    "if not os.path.exists(persistent_directory):\n",
    "    create_vector_store()\n",
    "else:\n",
    "    print(\n",
    "        f\"Vector store {persistent_directory} already exists. No need to initialize.\")\n",
    "\n",
    "# Load the vector store with the embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = Chroma(persist_directory=persistent_directory,\n",
    "            embedding_function=embeddings)\n",
    "    \n",
    "    \n",
    "# Step 5: Query the vector store\n",
    "def query_vector_store(query):\n",
    "    \"\"\"Query the vector store with the specified question.\"\"\"\n",
    "    # Create a retriever for querying the vector store\n",
    "    retriever = db.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3},\n",
    "    )\n",
    "\n",
    "    # Retrieve relevant documents based on the query\n",
    "    relevant_docs = retriever.invoke(query)\n",
    "\n",
    "    # Display the relevant results with metadata\n",
    "    print(\"\\n--- Relevant Documents ---\")\n",
    "    for i, doc in enumerate(relevant_docs, 1):\n",
    "        print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "        if doc.metadata:\n",
    "            print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")\n",
    "\n",
    "\n",
    "# Define the user's question\n",
    "query = \"Apple Intelligence?\"\n",
    "\n",
    "# Query the vector store with the user's question\n",
    "query_vector_store(query)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

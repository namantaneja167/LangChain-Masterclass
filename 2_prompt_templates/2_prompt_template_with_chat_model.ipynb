{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ChatOpenAI model\n",
    "model = ChatOllama(model=\"llama3:8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1: Create a ChatPromptTemplate using a template string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Prompt from Template-----\n",
      "Why did the cat join a band?\n",
      "\n",
      "Because it wanted to be the purr-cussionist!\n"
     ]
    }
   ],
   "source": [
    "print(\"-----Prompt from Template-----\")\n",
    "template = \"Tell me a joke about {topic}.\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt = prompt_template.invoke({\"topic\": \"cats\"})\n",
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2: Prompt with Multiple Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Prompt with Multiple Placeholders -----\n",
      "\n",
      "Let me think for a moment... Okay, here's one!\n",
      "\n",
      "So, there was once a panda named Ping who loved to eat bamboo shoots. Like, seriously loved them. One day, while munching away on his favorite snack, Ping got so carried away that he accidentally turned himself into a giant bamboo shoot!\n",
      "\n",
      "As you can imagine, this caused quite the commotion in the panda community! His friends were like, \"Ping, what's going on? You're... um... sprouting leaves and everything!\"\n",
      "\n",
      "Ping was mortified. He didn't know how to get back to normal. So, he decided to just roll with it (literally!) and start a bamboo-themed amusement park.\n",
      "\n",
      "The next thing you knew, Ping's Bamboo-licious World was the hottest attraction in town! Pandas from all over came to ride the Shoot-a-Coaster, play games like \"Pin the Leaf on the Panda,\" and even try their paw at being a giant bamboo shoot themselves!\n",
      "\n",
      "Who knew turning yourself into a vegetable could be so... fruitful?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n----- Prompt with Multiple Placeholders -----\\n\")\n",
    "template_multiple = \"\"\"You are a helpful assistant.\n",
    "Human: Tell me a {adjective} short story about a {animal}.\n",
    "Assistant:\"\"\"\n",
    "prompt_multiple = ChatPromptTemplate.from_template(template_multiple)\n",
    "prompt = prompt_multiple.invoke({\"adjective\": \"funny\", \"animal\": \"panda\"})\n",
    "\n",
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 3: Prompt with System and Human Messages (Using Tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Prompt with System and Human Messages (Tuple) -----\n",
      "\n",
      "Here we go!\n",
      "\n",
      "1. Why did the lawyer's dog go to the vet?\n",
      "\n",
      "Because it was feeling ruff... and needed some paws-itive legal representation! (get it? like \"ruff\" but also a law firm?)\n",
      "\n",
      "2. What do you call a lawyer who's having a bad hair day?\n",
      "\n",
      "A brief-less disaster! (ba-dum-tss)\n",
      "\n",
      "3. Why did the lawyer become a baker?\n",
      "\n",
      "Because he kneaded the dough, not a jury verdict! (haha, see what I did there?)\n",
      "\n",
      "Hope those made you LOL!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n----- Prompt with System and Human Messages (Tuple) -----\\n\")\n",
    "messages = [\n",
    "    (\"system\", \"You are a comedian who tells jokes about {topic}.\"),\n",
    "    (\"human\", \"Tell me {joke_count} jokes.\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke({\"topic\": \"lawyers\", \"joke_count\": 3})\n",
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

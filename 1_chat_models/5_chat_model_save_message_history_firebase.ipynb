{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Source: https://python.langchain.com/v0.2/docs/integrations/memory/google_firestore/\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import firestore\n",
    "from langchain_google_firestore import FirestoreChatMessageHistory\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "\"\"\"\n",
    "Steps to replicate this example:\n",
    "1. Create a Firebase account\n",
    "2. Create a new Firebase project\n",
    "    - Copy the project ID\n",
    "3. Create a Firestore database in the Firebase project\n",
    "4. Install the Google Cloud CLI on your computer\n",
    "    - https://cloud.google.com/sdk/docs/install\n",
    "    - Authenticate the Google Cloud CLI with your Google account\n",
    "        - https://cloud.google.com/docs/authentication/provide-credentials-adc#local-dev\n",
    "    - Set your default project to the new Firebase project you created\n",
    "5. Enable the Firestore API in the Google Cloud Console:\n",
    "    - https://console.cloud.google.com/apis/enableflow?apiid=firestore.googleapis.com&project=crewai-automation\n",
    "\"\"\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Setup Firebase Firestore\n",
    "PROJECT_ID = \"langchain-demo-abf48\"\n",
    "SESSION_ID = \"user_session_new\"  # This could be a username or a unique ID\n",
    "COLLECTION_NAME = \"chat_history\"\n",
    "\n",
    "# Initialize Firestore Client\n",
    "print(\"Initializing Firestore Client...\")\n",
    "client = firestore.Client(project=PROJECT_ID)\n",
    "\n",
    "# Initialize Firestore Chat Message History\n",
    "print(\"Initializing Firestore Chat Message History...\")\n",
    "chat_history = FirestoreChatMessageHistory(\n",
    "    session_id=SESSION_ID,\n",
    "    collection=COLLECTION_NAME,\n",
    "    client=client,\n",
    ")\n",
    "print(\"Chat History Initialized.\")\n",
    "print(\"Current Chat History:\", chat_history.messages)\n",
    "\n",
    "# Initialize Chat Model\n",
    "model = ChatOllama(model=\"llama3:8b\")\n",
    "\n",
    "print(\"Start chatting with the AI. Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    human_input = input(\"User: \")\n",
    "    if human_input.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    chat_history.add_user_message(human_input)\n",
    "\n",
    "    ai_response = model.invoke(chat_history.messages)\n",
    "    chat_history.add_ai_message(ai_response.content)\n",
    "\n",
    "    print(f\"AI: {ai_response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
